{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speckle Reducing Anisotropic Diffusion, Yongjian Yu and Scott T. Acton, Senior Member, IEEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy import signal\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 0.001\n",
    "\n",
    "def laplacian(image: np.array) -> np.array: \n",
    "    \"\"\"Eq. (15)\"\"\"\n",
    "    len_y, len_x = image.shape\n",
    "    image_new = np.zeros([len_y, len_x], dtype=np.float32)\n",
    "    for j in range(1, len_y-1):\n",
    "        for i in range(1, len_x-1):\n",
    "            image_new[j,i] = (image[j-1,i] + image[j+1,i] + image[j,i-1] + image[j,i+1]) - 4 * image[j,i]\n",
    "    return image_new\n",
    "\n",
    "\n",
    "def SRAD(image: np.array, rho: float, n_diffusion: int) -> np.array:\n",
    "    \"\"\"Anisotropic Diffusion calculation\"\"\"\n",
    "    q0 = 1 # under Eq. (37)\n",
    "    for t in range(1, n_diffusion):\n",
    "        len_y = image.shape[0]\n",
    "        len_x = image.shape[1]\n",
    "        \n",
    "        I = np.zeros([len_y+2, len_x+2], dtype=np.float32)\n",
    "        I[1:len_y+1, 1:len_x+1] = image\n",
    "        \n",
    "        q0 = q0 * np.exp(-t*rho) # Eq. (37)\n",
    "        DL_x = signal.convolve2d(I, [[0,0,0],[0,1,-1],[0,0,0]], mode='same', boundary='symm') # Eq. (28)\n",
    "        DL_y = signal.convolve2d(I, [[0,-1,0],[0,1,0],[0,0,0]], mode='same', boundary='symm') # Eq. (28)\n",
    "        DR_x = signal.convolve2d(I, [[0,0,0],[1,-1,0],[0,0,0]], mode='same', boundary='symm') # Eq. (29)\n",
    "        DR_y = signal.convolve2d(I, [[0,0,0],[0,-1,0],[0,1,0]], mode='same', boundary='symm') # Eq. (29)\n",
    "\n",
    "        D_I =  np.sqrt(DL_x**2 + DL_y**2 + DR_x**2 + DR_y**2) / np.sqrt(2) # under Eq. (29)\n",
    "        q = np.sqrt((1/2 * D_I**2 + 1/16 * laplacian(I)**2) / (I + 1/4 * laplacian(I) + EPSILON)**2)  # Eq. (31)\n",
    "        \n",
    "        c = 1 / (1 + ((q**2 - q0**2)/(q0**2 * (1 + q0**2)))) # Eq. (33)\n",
    "        d_t = signal.convolve2d(c, [[0,0,0],[0,0,-1],[0,0,0]],  mode='same', boundary='symm') * \\\n",
    "              signal.convolve2d(I, [[0,0,0],[0,1,-1],[0,0,0]], mode='same', boundary='symm') +  \\\n",
    "              signal.convolve2d(c, [[0,0,0],[0,-1,0],[0,0,0]],  mode='same', boundary='symm') * \\\n",
    "              signal.convolve2d(I, [[0,0,0],[-1,1,0],[0,0,0]], mode='same', boundary='symm') +  \\\n",
    "              signal.convolve2d(c, [[0,-1,0],[0,0,0],[0,0,0]],  mode='same', boundary='symm') * \\\n",
    "              signal.convolve2d(I, [[0,-1,0],[0,1,0],[0,0,0]], mode='same', boundary='symm') +  \\\n",
    "              signal.convolve2d(c, [[0,0,0],[0,-1,0],[0,0,0]],  mode='same', boundary='symm') * \\\n",
    "              signal.convolve2d(I, [[0,0,0],[0,1,0],[0,-1,0]], mode='same', boundary='symm')\n",
    "        I = I + rho/4 * d_t  # Eq. (61)\n",
    "        image = I[1:len_y+1, 1:len_x+1]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fuzzy_cluster: # see https://www.geeksforgeeks.org/ml-fuzzy-clustering/\n",
    "    def __init__(self, n_clusters=10, max_iter=100, m=2, error=1e-5, random_state=42):\n",
    "        self.gamma = None\n",
    "        self.centers = None\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.m = m #  fuzziness parameter \n",
    "        self.error = error\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, image_vec):\n",
    "        n_pixels = image_vec.shape[0]\n",
    "        C = self.n_clusters\n",
    "        centers = []\n",
    "        \n",
    "        r = np.random.RandomState(self.random_state)\n",
    "        gamma = r.rand(n_pixels, C) # init the cluster memberships of each point in image_vec\n",
    "        gamma = gamma / np.tile(gamma.sum(axis=1)[np.newaxis].T, C) # normalizing the memberships \n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            temp_gamma = gamma.copy()\n",
    "            centers = self.new_centers(image_vec, gamma)\n",
    "            gamma = self.new_gamma(image_vec, centers)\n",
    "            if norm(gamma - temp_gamma) < self.error:\n",
    "                break\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.centers = centers\n",
    "        return self\n",
    "\n",
    "    def new_centers(self, image_vec, gamma):\n",
    "        \"\"\"find out the centroid\"\"\"\n",
    "        gamma_m = gamma ** self.m\n",
    "        return (image_vec.T @ gamma_m / np.sum(gamma_m, axis=0)).T\n",
    "\n",
    "    def new_gamma(self, image_vec, centers):\n",
    "        \"\"\"updating membership values\"\"\"\n",
    "        temp = cdist(image_vec, centers) ** self.m\n",
    "        denominator_ = temp.reshape((image_vec.shape[0], 1, -1)).repeat(temp.shape[-1], axis=1)\n",
    "        denominator_ = temp[:, :, np.newaxis] / denominator_\n",
    "        \n",
    "        return 1 / denominator_.sum(2) ** (1 / (self.m - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_clustering(image, second_cluster_size=5, precentile_h=1.25 , precentile_l=0.9):\n",
    "    \"\"\" preclassification by hierarchical clustering.\n",
    "        pixels with high probability to be changed are labeled 2.\n",
    "        pixels with uncertainty are labeled 1.\n",
    "        pixels with high probability to be unchanged are labeled 0.\n",
    "       \"\"\"\n",
    "    len_y, len_x = image.shape\n",
    "    pix_vec = image.reshape([len_y * len_x, 1])\n",
    "    \n",
    "    # 1st clustering#\n",
    "    fcm = fuzzy_cluster(n_clusters=2)\n",
    "    fcm.fit(pix_vec)\n",
    "    fcm_lab = fcm.gamma.argmax(axis=1)\n",
    "   \n",
    "    if sum(fcm_lab==0)<sum(fcm_lab==1):\n",
    "        ttr = round(sum(fcm_lab==0) * precentile_h)\n",
    "        ttl = round(sum(fcm_lab==0) * precentile_l)\n",
    "    else:\n",
    "        ttr = round(sum(fcm_lab==1) * precentile_h)\n",
    "        ttl = round(sum(fcm_lab==1) * precentile_l)\n",
    "        \n",
    "     # 2nd clustering#\n",
    "    fcm = fuzzy_cluster(n_clusters=second_cluster_size)\n",
    "    fcm.fit(pix_vec)\n",
    "    fcm_lab  = fcm.gamma.argmax(axis=1)\n",
    "    idx = []\n",
    "    idx_tmp = []\n",
    "    idxmean = []\n",
    "    res_lab = np.zeros(len_y*len_x, dtype=np.float32)\n",
    "    for i in range(0, second_cluster_size):\n",
    "        idx_tmp.append(np.argwhere(fcm_lab==i))\n",
    "        idxmean.append(image.reshape(len_y*len_x, 1)[idx_tmp[i]].mean())\n",
    "    \n",
    "    idx_sort = np.argsort(idxmean)\n",
    "    for i in range(0, second_cluster_size):\n",
    "        idx.append(idx_tmp[idx_sort[i]])\n",
    "    \n",
    "    loc = second_cluster_size - 1\n",
    "    c = len(idx[loc])\n",
    "    res_lab[idx[loc]] = 2\n",
    "    flag_mid = 0\n",
    "    for i in range(1, second_cluster_size):\n",
    "        c = c + len(idx[loc-i])\n",
    "        \n",
    "        if c < ttl:\n",
    "            res_lab[idx[loc-i]] = 2\n",
    "        elif c >= ttl and c < ttr:\n",
    "            res_lab[idx[loc-i]] = 1\n",
    "            flag_mid = 1\n",
    "        elif flag_mid == 0:\n",
    "            res_lab[idx[loc-i]] = 1\n",
    "            flag_mid = 1\n",
    "    res_lab = res_lab.reshape(len_y, len_x)\n",
    "    return res_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1_path  = 'ottawa_1.bmp'\n",
    "im2_path  = 'ottawa_2.bmp'\n",
    "rho = 0.15 # diffusion parameter\n",
    "n_times = 6 # number of times performing diffusion \n",
    "im1 = io.imread(im1_path)[:,:,0].astype(np.float32)\n",
    "im2 = io.imread(im2_path)[:,:,0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_log_diff = np.log(SRAD(im1, rho, n_times) + 1) - np.log(SRAD(im2, rho, n_times) + 1) # calculating logarithmic difference\n",
    "im_diff = SRAD(im_log_diff, rho, n_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting 1st clustering\n",
      "starting 2nd clustering\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., ..., 0., 2., 2.],\n",
       "       [1., 1., 0., ..., 0., 1., 2.],\n",
       "       [1., 0., 0., ..., 0., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 1., 1.],\n",
       "       [1., 2., 0., ..., 2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pixels with high probability to be changed are labeled 2.\n",
    "# pixels with uncertainty are labeled 1.\n",
    "# pixels with high probability to be unchanged are labeled 0.\n",
    "hierarchical_clustering(im_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
